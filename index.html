<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AnomalyGPT">
  <meta name="keywords" content="AD, open-source, multimodal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AnomalyGPT</title>

  <meta name="google-site-verification" content="6lbYN1vX7A4sD8SrVniq84UEKyEUSBgxeP7d3FjuuK0" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <!-- <link rel="icon" href="./static/images/icon.png"> -->
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="shortcut icon" href="path/to/favicon.ico" type="image/x-icon">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  </head>

  <style>

    #main{
        position: relative;;
        width: 1200px;
    }

    .box{
        float: left;
        padding: 15px 0 0 15px;
/*        background-color: red;*/
    }

    .pic{
        width: 500px;
        padding: 10px;
        border: 1px solid #ccc;
        border-radius: 5px;
        background-color: #fff;
    }

    .pic img{
        width: 500px;
    }

  </style>



  <body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AnomalyGPT: </h1>
          <h2 class="title is-2 publication-title">Detecting Industrial Anomalies using Large <br> Vision-Language Models</h2>
          <div class="is-size-5">
            <span class="author-block">
                <a href="" style="font-weight:normal;">Zhaopeng Gu<sup>1,2</sup></a>,                
            </span>
            <span class="author-block">
              <a href="" style="font-weight:normal;">Bingke Zhu<sup>1,3,4</sup></a>,
            </span>
            <span class="author-block">
              <a href="" style="font-weight:normal;">Guibo Zhu<sup>1,4</sup></a>,                
          </span>
          <span class="author-block">
            <a href="" style="font-weight:normal;">Yingying Chen<sup>1,3,4</sup></a>,
          </span>
          <span class="author-block">
            <a href="" style="font-weight:normal;">Ming Tang<sup>1,2</sup></a>,                
        </span>
        <span class="author-block">
          <a href="" style="font-weight:normal;">Jinqiao Wang<sup>1,2,3,4</sup></a>
        </span>

        <br>
            
          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color: #3273DC;font-weight:normal"> <sup>1</sup> </b>Foundation Model Research Center, Institute of Automation, Chinese Academy of Sciences</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color: #3273DC;font-weight:normal"> <sup>2</sup> </b>University of Chinese Academy of Sciences &nbsp;&nbsp; </span>
            <span class="author-block"><b style="color: #3273DC;font-weight:normal"> <sup>3</sup> </b>Objecteye Inc. &nbsp;&nbsp;</span>
            <span class="author-block"><b style="color: #3273DC;font-weight:normal"> <sup>4</sup> </b>Wuhan AI Research </span>
          </div>


          <br>


          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <span class="link-block">
                <a href="https://github.com/CASIA-IVA-Lab/AnomalyGPT" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <span class="link-block">
                      <a href="" target="_blank"
                         class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        ðŸ¤—
                      </span>
                      <span>Demo</span>
                    </a>
                  </span>
              
              
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=lcxBfy0YnNA" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                  </a>
              </span>
              
              <span class="link-block">
                <a href="https://huggingface.co/FantasticGNU/AnomalyGPT" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-laugh"></i>
                  </span>
                  <span>Model</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<link rel="stylesheet" type="text/css" href="js/simple_style.css" />
<script type="text/javascript" src="js/simple_swiper.js"></script>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have demonstrated the capability of understanding images and achieved remarkable performance in various visual tasks. Despite their strong abilities in recognizing common objects due to extensive training datasets, they lack specific domain knowledge and have a weaker understanding of localized details within objects, which hinders their effectiveness in the Industrial Anomaly Detection (IAD) task. On the other hand, most existing IAD methods only provide anomaly scores and necessitate the manual setting of thresholds to distinguish between normal and abnormal samples, which restricts their practical implementation. In this paper, we explore the utilization of LVLM to address the IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM. We generate training data by simulating anomalous images and producing corresponding textual descriptions for each image. We also employ an image decoder to provide fine-grained semantic and design a prompt learner to fine-tune the LVLM using prompt embeddings. Our AnomalyGPT eliminates the need for manual threshold adjustments, thus directly assesses the presence and locations of anomalies. Additionally, AnomalyGPT supports multi-turn dialogues and exhibits impressive few-shot in-context learning capabilities. With only one normal shot, AnomalyGPT achieves the state-of-the-art performance with an accuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3% on the MVTec-AD dataset.
</b>
          </p>
        </div>
      </div>
    </div>

    <br>
    <br>
    <div class="container">
            <!-- Paper video. -->
            <h2 class="title has-text-centered">Video Presentation</h2>
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">

                    <div class="publication-video">
                        <!-- Youtube embed code here -->
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/lcxBfy0YnNA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    <br>
    <br>
    <!-- Paper Model. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Model</h2>
        <div class="content has-text-justified">
          <p>
            <b>AnomalyGPT</b> is the first Large Vision-Language Model (LVLM) based Industrial Anomaly Detection (IAD) method that can detect anomalies in industrial images without the need for manually specified thresholds. Existing IAD methods can only provide anomaly scores and need manually threshold setting, while existing LVLMs cannot detect anomalies in the image. AnomalyGPT can not only indicate the presence and location of anomaly but also provide information about the image.
          </p>
          <p align='center'>
            <img id="model" width="70%" src="images/compare.png">
          </p>
          <h4 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman"><b>Comparison between AnomalyGPT and existing methods.</b></p>
          </h3>
          <p>
            We leverage a pre-trained image encoder and a Large Language Model (LLM) to align IAD images and their corresponding textual descriptions via simulated anomaly data. We employ a lightweight, visual-textual feature-matching-based image decoder to obtain localization result, and design a prompt learner to provide fine-grained semantic to LLM and fine-tune the LVLM using prompt embeddings. Our method can also detect anomalies for previously unseen items with few normal sample provided.  
            <!-- The query image is passed to the frozen image encoder and the patch-level features extracted from intermediate layers are fed into image decoder to compute their similarity with normal and abnormal texts to obtain localization result. The final features extracted by the image encoder are fed to a linear layer and then passed to the prompt learner along with the localization result. The prompt learner converts them into prompt embeddings suitable for input into the LLM together with user text inputs. In few-shot setting, the patch-level features from normal samples are stored in memory banks and the localization result can be obtained by calculating the distance between query patches and their most similar counterparts in the memory bank. -->
          </p>
          <!-- <ul>
            <li>A linear projection matrix connects the multimodal features from ImageBind to Vicuna</li>
            <li>Additional LoRA weights on the Vicunaâ€™s attention modules</li>

          </ul> -->
        </div>  
        <img id="model" width="100%" src="images/AnomalyGPT.png">
        <h3 class="subtitle has-text-centered">
          <p style="font-family:Times New Roman"><b>The architecture of AnomalyGPT.</b></p>
        </h3>

      </div>
    </div>
    <!-- <br>
    <br>
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Capabilities</h2>
          <div class="content has-text-justified">
            <p>
              Compared to existing IAD methods that can only provide anomaly scores and existing LVLMs that cannot detect anomalies in industrial images. AnomalyGPT can not only directly indicate the presence and location of anomaly without manually threshold setting but also provide information about the image. We find that the capabilities of AnomalyGPT include but are not limited to <b>(with examples attached in the bottom of this page):</b>
              <ul>
                <li><b>determining whether an image contains anomalies</b>.</li>
                <li><b>image/video inspired creative writing</b>. </li>
                <li><b>visual and auditory reasoning</b>.</li>
                <li><b>multimodal arithmetic</b>.</li>
                <li><b>...</b>. <span style="font-size: 95%;">(explore our <a href="">demo</a> on your own!)</li>
              </ul>  
           </p>
          </div>
        </div>
    </div>
  </div> -->
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{gu2023anomalygpt,
        title={AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models},
        author={Gu, Zhaopeng and Zhu, Bingke and Zhu, Guibo and Chen, Yingying and Tang, Ming and Wang, Jinqiao},
        journal={arXiv preprint arXiv:},
        year={2023}
      }
</code></pre>
  </div>
</section>

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This website template is borrowed from the <a
      href="https://minigpt-4.github.io/">MiniGPT-4</a> project, which is adapted from <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>

<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3">Examples</h2>
      </div>
    </div>
  </div>
  <!--/ Results. -->    
<div class="container is-max-desktop">
</section>


<script src="js/Underscore-min.js"></script>
<script src="js/index.js"></script>


<section class="section">
<div id="main">
  <div class="box"><div class="pic"><img src="demos/audio-dog.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/audio-gunshot.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/image-couple-audio-rain.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/image-dog.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/image-girl-audio-rain.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/image-musk.png" alt=""></div></div>

  <div class="box"><div class="pic"><img src="demos/image-woman-audio-ocean-waves.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/video-avengers.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/video-couple-audio-waves.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/video-noodle.png" alt=""></div></div>
  <div class="box"><div class="pic"><img src="demos/video-spacex-rocket.png" alt=""></div></div>

</div>

</section>



</body>

</html>
